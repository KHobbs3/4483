# write-up Outline :rocket:
(in reference to "Compiled Results" and "/Users/kt/Documents/Documents/4483E/")

## Figures/tables to include:
### CONTROL:
#### Positive:
  1. pipeline results table (Table 7)

#### Negative:
  1. table summarizing attempts

### TEST:
  1. effect plots (m/d)
  2. methods comparison (m/d)
  3. Deseq2 MA for m - Aldex2 MA for m
  4. filtR for (m/d)


## Supplementary data:
  1. MA for dada2 - all subgroups (Aldex2/Deseq2)[6]
  2. MA for other subgroups (m) [4]
  3. effect plots for other subgroups (m/d) [4]
  4. tables comparing SVs between groups (m/d) [4]
  5. dada2:
    1. err.pdf (t/c)[2]
    2. qualprofiles (t/c) [2]
  6. filtR graphs 

## Other data (unused):
  - PCA Biplots (m/d)
  - Deseq2 dispersion plots
  - MW plots from ALDEx


  m = mothur, d = dada2, t = test, c = control


## Tentative conclusions:
### CONTROL:
#### Positive:
- Since both QIIME and dada2 count tables did not generate technical errors (according to filtR), it is possible that dada2 found more SVs than QIIME due to its higher resolution.
- The additional SVs may represent biological variation that was falsely clustered using the OTU based approach to processing reads employed by QIIME.


#### Negative:
- Both dada2 and QIIME count tables do not include the synthetic variable regions possibly because they are filtered out due to
    - low abundances (most likely)
    - errors? (unlikely)
    - dada2 could have identified them as potential technical errors

### TEST:
- results are irreproducible due to lack of detailed reporting of methods by Jiang, et al


## Discussion:
- hypothesis tests used (in table contrasting methods)
- how effect plots work/why they are superior to hypothesis tests  (nature-effect(gloor).pdf)

## limitations:
- caveats in mothur analysis:
    - Jiang et al used custom python scripts to filter
    - exact primer sequences used are unknown
    - Silva reference db file may be different (not disclosed)
- negative control - what is happening with the spike-ins?
- processing pipelines are designed to detect true biological variants but there is currently no way to prove or disprove the validity of the claims
- comparing bacterial names is not ideal as there is so much discrepancy among databases when it comes to assigning taxonomies to sequence variants
    - using the same db can mediate this; however, Jiang et al did not disclose the version of Silva used

## POTENTIAL CONCLUSIONS:
- it appears as though the discrepancy in the published results lies in the analytical tool DESeq2 as opposed to in the OTU-based mothur pipeline, which, according to filtR, produces no technical variants.
- dada2 consistently detected more SVs than the OTU-based pipelines used in the test and control with no technical variants. This seems to suggest that dada2's higher resolution permits for a more thorough and robust distinction of true biological variants.
  This also suggests that biological variants are likely to be falsely clustered in OTU generation thus generating results with false negatives.
- reproducibility problem in science
  - future directions
